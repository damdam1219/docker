{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6294644-2cba-499c-b727-318d4116feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"spark_sql_basic2\")\n",
    "sc   = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27718ad-0acf-4048-9bd2-37cd701a687e",
   "metadata": {},
   "source": [
    "# RDD만을 이용한 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f608a083-4328-40fc-865a-70243b997cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_rdd = sc.parallelize([\n",
    "    (1, (\"어벤져스\", \"마블\")),\n",
    "    (2, (\"슈퍼맨\", \"DC\")),\n",
    "    (3, (\"배트맨\", \"DC\")),\n",
    "    (4, (\"겨울왕국\", \"디즈니\")),\n",
    "    (5, (\"아이언맨\", \"마블\"))\n",
    "])\n",
    "\n",
    "\n",
    "attendances_rdd = sc.parallelize([\n",
    "    (1, (13934592, \"KR\")),\n",
    "    (2, (2182227,\"KR\")),\n",
    "    (3, (4226242, \"KR\")),\n",
    "    (4, (10303058, \"KR\")),\n",
    "    (5, (4300365, \"KR\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f38d260f-203b-4e5b-a862-a21804d4fb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, (('슈퍼맨', 'DC'), (2182227, 'KR'))),\n",
       " (4, (('겨울왕국', '디즈니'), (10303058, 'KR'))),\n",
       " (1, (('어벤져스', '마블'), (13934592, 'KR'))),\n",
       " (3, (('배트맨', 'DC'), (4226242, 'KR'))),\n",
       " (5, (('아이언맨', '마블'), (4300365, 'KR')))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마블 영화 중 관객 수가 500만 이상인 영화를 가져오기\n",
    "\n",
    "# CASE1. join 먼저, filter 나중에\n",
    "movie_att = movies_rdd.join(attendances_rdd)\n",
    "movie_att.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00032d8b-74d4-4228-91d1-df10b99aafb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (('어벤져스', '마블'), (13934592, 'KR')))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_att.filter(\n",
    "    lambda x : x[1][0][1] == \"마블\" and x[1][1][0] > 5000000\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa3d2cc8-400e-4679-a7b8-01e165ccd507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (('어벤져스', '마블'), (13934592, 'KR')))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CASE 2. filter 먼저, join 나중에\n",
    "filtered_movies = movies_rdd.filter(lambda x : x[1][1] == '마블')\n",
    "filtered_att = attendances_rdd.filter(lambda x : x[1][0] > 5000000)\n",
    "\n",
    "filtered_movies.join(filtered_att).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8b0a22-21b0-4172-b6ee-a3471e55b884",
   "metadata": {},
   "source": [
    "choice CASE2 > 초반에 필터를 하고 join을 하는게 더 효율적임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ccb104a-63f8-4749-8e04-155ef81c16ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61ce366-bda7-442f-80bd-26f6b3e35c0d",
   "metadata": {},
   "source": [
    "# Spark SQL 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77b80967-9721-4078-aaba-2115f0cfd62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"spark-sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0cebe9-1ccc-4baf-9b13-a702fa92411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼 추가\n",
    "movies = [\n",
    "    (1, \"어벤져스\", \"마블\", 2012, 4, 26),\n",
    "    (2, \"슈퍼맨\", \"DC\", 2013, 6, 13),\n",
    "    (3, \"배트맨\", \"DC\", 2008, 8, 6),\n",
    "    (4, \"겨울왕국\", \"디즈니\", 2014, 1, 16),\n",
    "    (5, \"아이언맨\", \"마블\", 2008, 4, 30)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f88cc6c-ddef-4f72-848c-1fbafbf5bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#스키마를 알아야 한다.\n",
    "movie_schema = [\"id\", \"name\", \"company\", \"year\", \"month\", \"day\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2e436e-bc13-4828-923b-be656d87662a",
   "metadata": {},
   "source": [
    "## 데이터 프레임 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f3bc8f4-06ef-4c4c-8500-243f50824379",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=movies, schema=movie_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21d4e839-7e1c-4097-8a01-a092190685de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'),\n",
       " ('name', 'string'),\n",
       " ('company', 'string'),\n",
       " ('year', 'bigint'),\n",
       " ('month', 'bigint'),\n",
       " ('day', 'bigint')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28359ec0-0886-4687-8ced-0ae83be4f551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    name|\n",
      "+--------+\n",
      "|어벤져스|\n",
      "|  슈퍼맨|\n",
      "|  배트맨|\n",
      "|겨울왕국|\n",
      "|아이언맨|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03dae5ed-7895-4c5e-ad9f-4b6fca97d46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+-----+---+\n",
      "| id|    name|company|year|month|day|\n",
      "+---+--------+-------+----+-----+---+\n",
      "|  1|어벤져스|   마블|2012|    4| 26|\n",
      "|  2|  슈퍼맨|     DC|2013|    6| 13|\n",
      "|  3|  배트맨|     DC|2008|    8|  6|\n",
      "|  4|겨울왕국| 디즈니|2014|    1| 16|\n",
      "|  5|아이언맨|   마블|2008|    4| 30|\n",
      "+---+--------+-------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d942a622-f6cc-4318-b9e8-61e772e56643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+-----+---+\n",
      "| id|    name|company|year|month|day|\n",
      "+---+--------+-------+----+-----+---+\n",
      "|  1|어벤져스|   마블|2012|    4| 26|\n",
      "|  2|  슈퍼맨|     DC|2013|    6| 13|\n",
      "|  4|겨울왕국| 디즈니|2014|    1| 16|\n",
      "+---+--------+-------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.year >= 2010).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19f7ccf4-e008-41bf-af90-3c2f949053f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+\n",
      "|year|month|day|\n",
      "+----+-----+---+\n",
      "|2012|    4| 26|\n",
      "|2013|    6| 13|\n",
      "|2008|    8|  6|\n",
      "|2014|    1| 16|\n",
      "|2008|    4| 30|\n",
      "+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('year','month','day').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f3bfe85-db76-4da3-85da-fd346c16e6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+-----+---+\n",
      "| id|    name|company|year|month|day|\n",
      "+---+--------+-------+----+-----+---+\n",
      "|  1|어벤져스|   마블|2012|    4| 26|\n",
      "|  2|  슈퍼맨|     DC|2013|    6| 13|\n",
      "|  4|겨울왕국| 디즈니|2014|    1| 16|\n",
      "+---+--------+-------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.year > 2008).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "590379cc-407d-46f0-9d98-55de1b8a27b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+-----+---+\n",
      "| id|    name|company|year|month|day|\n",
      "+---+--------+-------+----+-----+---+\n",
      "|  1|어벤져스|   마블|2012|    4| 26|\n",
      "|  5|아이언맨|   마블|2008|    4| 30|\n",
      "+---+--------+-------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.company == '마블').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0419d99f-03ba-414b-85a5-70e2a598ae7a",
   "metadata": {},
   "source": [
    "## 뷰 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba814f00-059d-40ba-ba2b-95a377444b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"movies\")\n",
    "# PySpark에서 DataFrame을 SQL 테이블처럼 쓰기 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f2f5069-1e0d-4e48-a6f5-aad0cf7aa089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    name|\n",
      "+--------+\n",
      "|어벤져스|\n",
      "|  슈퍼맨|\n",
      "|  배트맨|\n",
      "|겨울왕국|\n",
      "|아이언맨|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 영화 이름만 가져오기\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "SELECT name\n",
    "  FROM movies\n",
    "\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e03ea3e-0d50-4f99-b942-549db46d8981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|    NAME|YEAR|\n",
      "+--------+----+\n",
      "|어벤져스|2012|\n",
      "|  슈퍼맨|2013|\n",
      "|겨울왕국|2014|\n",
      "+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2010 년 이후에 개봉한 영화 조회\n",
    "\n",
    "query = '''\n",
    "SELECT NAME,YEAR FROM MOVIES WHERE YEAR > 2010\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78f40030-5d46-4022-b07e-1e3624a1309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+-----+---+\n",
      "| id|    name|company|year|month|day|\n",
      "+---+--------+-------+----+-----+---+\n",
      "|  2|  슈퍼맨|     DC|2013|    6| 13|\n",
      "|  3|  배트맨|     DC|2008|    8|  6|\n",
      "|  5|아이언맨|   마블|2008|    4| 30|\n",
      "+---+--------+-------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# like 문자열 데이터에서 특정 단어나 문장을 포함한 데이터를 찾을 때\n",
    "# % 기호를 사용해서 문장이 매칭되는지 확인 가능!\n",
    "# 제목이 ~~맨으로 끝나는 데이터의 모든 정보를 조회\n",
    "\n",
    "query = '''\n",
    "SELECT * FROM MOVIES WHERE NAME LIKE\"%맨\"\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78848dd2-7cae-4e64-a9c0-27ce4ab4f4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+----+-----+---+\n",
      "| id|    name|company|year|month|day|\n",
      "+---+--------+-------+----+-----+---+\n",
      "|  1|어벤져스|   마블|2012|    4| 26|\n",
      "|  2|  슈퍼맨|     DC|2013|    6| 13|\n",
      "|  3|  배트맨|     DC|2008|    8|  6|\n",
      "|  5|아이언맨|   마블|2008|    4| 30|\n",
      "+---+--------+-------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BETWEEN 특정 데이터와 데이터 사이를 조회\n",
    "\n",
    "# 개봉 월이 4 ~ 8월 사이. 4 <= 개봉월 <= 8\n",
    "\n",
    "query = '''\n",
    "SELECT * FROM MOVIES WHERE MONTH BETWEEN 4 AND 8\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "daa67b08-0dfe-467f-a820-fec4ccbdb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join 구현하기\n",
    "\n",
    "attendances = [\n",
    "    (1, 13934592., \"KR\"),\n",
    "    (2, 2182227.,\"KR\"),\n",
    "    (3, 4226242., \"KR\"),\n",
    "    (4, 10303058., \"KR\"),\n",
    "    (5, 4300365., \"KR\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc83242c-a827-47fd-aa2a-40564419a4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직접 스키마 지정해 보기\n",
    "from pyspark.sql.types import StringType, FloatType\\\n",
    "    , IntegerType\\\n",
    "    , StructType, StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66dda048-2d9d-450d-9cc8-fbf7a9276cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_schema = StructType([ # 모든 컬럼의 타입을 통칭 - 컬럼 데이터의 집합\n",
    "    StructField(\"id\", IntegerType(), True), # StructField : 컬럼\n",
    "    StructField(\"att\", FloatType(), True),\n",
    "    StructField(\"theater_country\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c3ff0cc-0987-405f-9476-fd5e2c704182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'int'), ('att', 'float'), ('theater_country', 'string')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_df = spark.createDataFrame(\n",
    "    data=attendances,\n",
    "    schema=att_schema\n",
    ")\n",
    "\n",
    "att_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "279a83b6-9dfb-4599-9305-2ada66c09451",
   "metadata": {},
   "outputs": [],
   "source": [
    "att_df.createOrReplaceTempView(\"att\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c35b8d9-ced9-42d9-a1a0-b0c1af67f277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---------------+\n",
      "| id|        att|theater_country|\n",
      "+---+-----------+---------------+\n",
      "|  1|1.3934592E7|             KR|\n",
      "|  2|  2182227.0|             KR|\n",
      "|  3|  4226242.0|             KR|\n",
      "|  4|1.0303058E7|             KR|\n",
      "|  5|  4300365.0|             KR|\n",
      "+---+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "att_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fdd2ae10-b1dc-4a0a-b35f-2a5e75a934c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+-----------+\n",
      "| ID|    NAME|COMPANY|        ATT|\n",
      "+---+--------+-------+-----------+\n",
      "|  1|어벤져스|   마블|1.3934592E7|\n",
      "|  2|  슈퍼맨|     DC|  2182227.0|\n",
      "|  3|  배트맨|     DC|  4226242.0|\n",
      "|  4|겨울왕국| 디즈니|1.0303058E7|\n",
      "|  5|아이언맨|   마블|  4300365.0|\n",
      "+---+--------+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join\n",
    "\n",
    "query = '''\n",
    "SELECT MOVIES.ID, MOVIES.NAME, MOVIES.COMPANY, ATT.ATT\n",
    "FROM MOVIES\n",
    "JOIN ATT ON MOVIES.ID = ATT.ID\n",
    "\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d6e2d61-3450-4749-9ab5-0f303d979149",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef03c0-752e-4a27-8d63-59b742b3a43d",
   "metadata": {},
   "source": [
    "# SQL최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50e126f4-e43c-4571-839a-183b98166393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"trip_count_sql\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50330ec4-1a05-4a0f-9b46-f794e3c7cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_file = \"learning_spark_data/fhvhv_tripdata_2020-03.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0ad374d-4e24-4801-8314-fd02ec36b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferSchema : 자동으로 스키마 예측하게 하기\n",
    "data = spark.read.csv(trip_file, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11825527-1d39-438d-9868-740445ca0522",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.createOrReplaceTempView(\"mobility_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34985fc6-673f-44be-8d37-408a17944c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0005|              B02510|2020-03-01 00:03:40|2020-03-01 00:23:39|          81|         159|   NULL|\n",
      "|           HV0005|              B02510|2020-03-01 00:28:05|2020-03-01 00:38:57|         168|         119|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:03:07|2020-03-01 00:15:04|         137|         209|      1|\n",
      "|           HV0003|              B02764|2020-03-01 00:18:42|2020-03-01 00:38:42|         209|          80|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:44:24|2020-03-01 00:58:44|         256|         226|   NULL|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "select *\n",
    "from mobility_data\n",
    "limit 5\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab2850-4fd3-401a-8223-cd879b389dea",
   "metadata": {},
   "source": [
    "## 스파크 SQL을 사용하는 이유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c868c6cc-b776-4cb4-acea-236a7c1ca80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|pickup_date| trips|\n",
      "+-----------+------+\n",
      "| 2020-03-03|697880|\n",
      "| 2020-03-02|648986|\n",
      "| 2020-03-01|784246|\n",
      "| 2020-03-06|872012|\n",
      "| 2020-03-05|731165|\n",
      "| 2020-03-04|707879|\n",
      "| 2020-03-09|628940|\n",
      "| 2020-03-08|731222|\n",
      "| 2020-03-07|886071|\n",
      "| 2020-03-10|626474|\n",
      "| 2020-03-12|643257|\n",
      "| 2020-03-11|628601|\n",
      "| 2020-03-16|391518|\n",
      "| 2020-03-13|660914|\n",
      "| 2020-03-15|448125|\n",
      "| 2020-03-14|569397|\n",
      "| 2020-03-26|141607|\n",
      "| 2020-03-25|141088|\n",
      "| 2020-03-20|261900|\n",
      "| 2020-03-24|141686|\n",
      "+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "select split(pickup_datetime, ' ')[0] as pickup_date, count(*) as trips\n",
    "from mobility_data\n",
    "\n",
    "group by pickup_date\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3beb9cc9-c3ed-4f07-8d92-0294e4ff528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Aggregate ['pickup_date], ['split('pickup_datetime,  )[0] AS pickup_date#382, 'count(1) AS trips#383]\n",
      "+- 'UnresolvedRelation [mobility_data], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "pickup_date: string, trips: bigint\n",
      "Aggregate [split(cast(pickup_datetime#309 as string),  , -1)[0]], [split(cast(pickup_datetime#309 as string),  , -1)[0] AS pickup_date#382, count(1) AS trips#383L]\n",
      "+- SubqueryAlias mobility_data\n",
      "   +- View (`mobility_data`, [hvfhs_license_num#307,dispatching_base_num#308,pickup_datetime#309,dropoff_datetime#310,PULocationID#311,DOLocationID#312,SR_Flag#313])\n",
      "      +- Relation [hvfhs_license_num#307,dispatching_base_num#308,pickup_datetime#309,dropoff_datetime#310,PULocationID#311,DOLocationID#312,SR_Flag#313] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [_groupingexpression#387], [_groupingexpression#387 AS pickup_date#382, count(1) AS trips#383L]\n",
      "+- Project [split(cast(pickup_datetime#309 as string),  , -1)[0] AS _groupingexpression#387]\n",
      "   +- Relation [hvfhs_license_num#307,dispatching_base_num#308,pickup_datetime#309,dropoff_datetime#310,PULocationID#311,DOLocationID#312,SR_Flag#313] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[_groupingexpression#387], functions=[count(1)], output=[pickup_date#382, trips#383L])\n",
      "   +- Exchange hashpartitioning(_groupingexpression#387, 200), ENSURE_REQUIREMENTS, [plan_id=428]\n",
      "      +- HashAggregate(keys=[_groupingexpression#387], functions=[partial_count(1)], output=[_groupingexpression#387, count#389L])\n",
      "         +- Project [split(cast(pickup_datetime#309 as string),  , -1)[0] AS _groupingexpression#387]\n",
      "            +- FileScan csv [pickup_datetime#309] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/work/learning_spark_data/fhvhv_tripdata_2020-03.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<pickup_datetime:timestamp>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 계획 살펴보기\n",
    "spark.sql(query).explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca09eeca-5a7a-4ec6-ba52-c278a95f984c",
   "metadata": {},
   "source": [
    "**Optimized Logical Plan**\n",
    "\n",
    "Spark Catalyst가 최적화한 로직.\n",
    "\n",
    "중간 컬럼명을 _groupingexpression#387 이런 내부 표현으로 치환해서 중복 제거\n",
    "\n",
    ", 필요 없는 컬럼 제거 등의 최적화를 수행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db2b30f7-0406-40ad-93b1-6ef9982057d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Aggregate ['pickup_date], ['pickup_date, 'count(1) AS trips#391]\n",
      "+- 'SubqueryAlias __auto_generated_subquery_name\n",
      "   +- 'Project ['split('pickup_datetime,  )[0] AS pickup_date#390]\n",
      "      +- 'UnresolvedRelation [mobility_data], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "pickup_date: string, trips: bigint\n",
      "Aggregate [pickup_date#390], [pickup_date#390, count(1) AS trips#391L]\n",
      "+- SubqueryAlias __auto_generated_subquery_name\n",
      "   +- Project [split(cast(pickup_datetime#309 as string),  , -1)[0] AS pickup_date#390]\n",
      "      +- SubqueryAlias mobility_data\n",
      "         +- View (`mobility_data`, [hvfhs_license_num#307,dispatching_base_num#308,pickup_datetime#309,dropoff_datetime#310,PULocationID#311,DOLocationID#312,SR_Flag#313])\n",
      "            +- Relation [hvfhs_license_num#307,dispatching_base_num#308,pickup_datetime#309,dropoff_datetime#310,PULocationID#311,DOLocationID#312,SR_Flag#313] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [pickup_date#390], [pickup_date#390, count(1) AS trips#391L]\n",
      "+- Project [split(cast(pickup_datetime#309 as string),  , -1)[0] AS pickup_date#390]\n",
      "   +- Relation [hvfhs_license_num#307,dispatching_base_num#308,pickup_datetime#309,dropoff_datetime#310,PULocationID#311,DOLocationID#312,SR_Flag#313] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[pickup_date#390], functions=[count(1)], output=[pickup_date#390, trips#391L])\n",
      "   +- Exchange hashpartitioning(pickup_date#390, 200), ENSURE_REQUIREMENTS, [plan_id=443]\n",
      "      +- HashAggregate(keys=[pickup_date#390], functions=[partial_count(1)], output=[pickup_date#390, count#396L])\n",
      "         +- Project [split(cast(pickup_datetime#309 as string),  , -1)[0] AS pickup_date#390]\n",
      "            +- FileScan csv [pickup_datetime#309] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/work/learning_spark_data/fhvhv_tripdata_2020-03.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<pickup_datetime:timestamp>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 두번째 쿼리\n",
    "spark.sql(\"\"\"select \n",
    "                pickup_date, \n",
    "                count(*) as trips\n",
    "             from ( select\n",
    "                          split(pickup_datetime, ' ')[0] as pickup_date\n",
    "                          from mobility_data )\n",
    "             group by pickup_date\"\"\").explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ec385d-8de3-433c-904e-e5beb647aa60",
   "metadata": {},
   "source": [
    "| 단계                     | 설명                              |\n",
    "| ---------------------- | ------------------------------- |\n",
    "| Parsed Logical Plan    | 구문 해석만 한 단계                     |\n",
    "| Analyzed Logical Plan  | 컬럼 존재 확인, 데이터 타입 분석             |\n",
    "| Optimized Logical Plan | 필요 없는 컬럼 제거, 내부 연산 단순화          |\n",
    "| Physical Plan          | 실제 실행 방식 결정 (파일 읽기, 파티셔닝, 집계 등) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f6a19-957c-4cf2-a2fa-aa7d5d113765",
   "metadata": {},
   "source": [
    "**🔍 두 쿼리의 공통 목적**\n",
    "    \n",
    "둘 다 목적은 pickup_datetime에서 날짜(pickup_date)를 추출한 뒤, \n",
    "    \n",
    "해당 날짜별로  **트립 수(trips)** 를 집계하는 것입니다.\n",
    "\n",
    "| 항목                                     | 첫 번째 쿼리                                                  | 두 번째 쿼리                                               |\n",
    "| -------------------------------------- | -------------------------------------------------------- | ----------------------------------------------------- |\n",
    "| 날짜 추출 위치                               | `'split(pickup_datetime, \" \")[0]`를 `Aggregate` 안에서 직접 사용 | 먼저 `Project`로 `pickup_date` 컬럼 생성한 후 `Aggregate`에서 사용 |\n",
    "| **Alias 이름**                           | `pickup_date#382` (split 바로 사용)                          | `pickup_date#390` (프로젝션에서 만든 컬럼)                      |\n",
    "| **Parsed Logical Plan**                | 날짜 파싱 연산이 `Aggregate` 안에 있음                              | 날짜 파싱은 `Project`, 집계는 그 위에서                           |\n",
    "| **SubqueryAlias 이름**                   | `mobility_data` 직접 사용                                    | `__auto_generated_subquery_name` (서브쿼리 감쌈)            |\n",
    "| **쿼리 재사용성**                            | 직접 표현 → 다소 비효율                                           | 컬럼 분리 → 재사용성과 최적화 용이                                  |\n",
    "| **실제 처리 구조 (Optimized/Physical Plan)** | 날짜 추출 → 그룹화 → 집계                                         | 날짜 추출 → 그룹화 → 집계 (거의 동일)                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77924618-6666-4174-9e8b-7cd09f13dfbe",
   "metadata": {},
   "source": [
    "**최적화 측면 비교**\n",
    "| 측면        | 첫 번째 쿼리     | 두 번째 쿼리                   |\n",
    "| --------- | ----------- | ------------------------- |\n",
    "| 중복 연산 제거  | ❌ split 반복됨 | ✅ 한번만 계산                  |\n",
    "| 최적화 플랜 구조 | 다소 중첩됨      | Project → Aggregate 명확 분리 |\n",
    "| 재사용성      | 떨어짐         | 높음                        |\n",
    "| 가독성       | 낮음          | 높음                        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39621bd7-5857-411b-b1f9-03085abd18a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8293cdc2-83e4-4bde-a564-ef7d12752995",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94af2c5d-cf8d-41ad-b7b3-57f86e63985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"data_eda\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11fabd17-f6be-4b89-bfe0-8f6cd58817e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_file = \"learning_spark_data/fhvhv_tripdata_2020-03.csv\"\n",
    "trip_data = spark.read.csv(trip_file, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c9212c9-aca0-487e-983e-1f8e6eec8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_file = \"learning_spark_data/taxi+_zone_lookup.csv\"\n",
    "zone_data = spark.read.csv(zone_file, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45b9eb97-6f85-4706-9185-1afd3fc768c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.createOrReplaceTempView(\"trip_data\")\n",
    "zone_data.createOrReplaceTempView(\"zone_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ededb38-e01a-4d58-ab19-88f67ce0b698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ce7da8b-7dda-49e6-93e9-d713b8a5d251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zone_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aca525-6973-40bd-a7f0-998e7bef286c",
   "metadata": {},
   "source": [
    "## 승차 Location(PULocationID)별 개수 세기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d547d732-c92e-4dfe-bbd8-bd64cb4da9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0005|              B02510|2020-03-01 00:03:40|2020-03-01 00:23:39|          81|         159|   NULL|\n",
      "|           HV0005|              B02510|2020-03-01 00:28:05|2020-03-01 00:38:57|         168|         119|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:03:07|2020-03-01 00:15:04|         137|         209|      1|\n",
      "|           HV0003|              B02764|2020-03-01 00:18:42|2020-03-01 00:38:42|         209|          80|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:44:24|2020-03-01 00:58:44|         256|         226|   NULL|\n",
      "|           HV0003|              B02682|2020-03-01 00:17:23|2020-03-01 00:39:35|          79|         263|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:01:18|2020-03-01 00:38:52|          61|          29|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:43:27|2020-03-01 00:47:27|         150|         150|      1|\n",
      "|           HV0003|              B02764|2020-03-01 00:52:23|2020-03-01 01:00:15|         150|         210|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:19:49|2020-03-01 00:23:40|          60|         167|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:29:34|2020-03-01 00:39:19|          47|         213|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:41:44|2020-03-01 00:58:13|         213|         235|   NULL|\n",
      "|           HV0003|              B02765|2020-03-01 00:11:26|2020-03-01 00:24:46|         243|         153|   NULL|\n",
      "|           HV0003|              B02765|2020-03-01 00:28:05|2020-03-01 00:38:56|         127|          18|   NULL|\n",
      "|           HV0003|              B02765|2020-03-01 00:44:28|2020-03-01 00:52:09|          18|         169|   NULL|\n",
      "|           HV0003|              B02765|2020-03-01 00:56:50|2020-03-01 00:59:26|          94|         169|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:56:14|2020-03-01 01:03:38|         211|         158|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:14:15|2020-03-01 00:26:47|         246|         107|   NULL|\n",
      "|           HV0003|              B02764|2020-03-01 00:31:38|2020-03-01 00:58:07|         234|           9|   NULL|\n",
      "|           HV0005|              B02510|2020-03-01 00:26:31|2020-03-01 00:38:07|         139|          10|      1|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT * FROM TRIP_DATA\n",
    "'''\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa3f918b-4f00-40a9-b469-6e3e59eaf4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|PULocationID| count|\n",
      "+------------+------+\n",
      "|         148|116205|\n",
      "|         243| 87431|\n",
      "|          31|  5285|\n",
      "|         137| 85552|\n",
      "|          85| 46120|\n",
      "|         251|  9080|\n",
      "|          65| 66622|\n",
      "|         255|113947|\n",
      "|          53| 17571|\n",
      "|         133| 27200|\n",
      "|          78| 76155|\n",
      "|         108| 20378|\n",
      "|         155| 39527|\n",
      "|         211| 61075|\n",
      "|         193| 20111|\n",
      "|          34| 11823|\n",
      "|         115| 10806|\n",
      "|         126| 52833|\n",
      "|         101|  8983|\n",
      "|          81| 41425|\n",
      "+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT PULocationID, COUNT(*) AS count\n",
    "FROM trip_data\n",
    "GROUP BY PULocationID\n",
    "'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a977a-fcc5-4fd2-b4fe-35d8bedd9328",
   "metadata": {},
   "source": [
    "## 하차 Location(DOLocationID)별 개수 세기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "81f0e7fb-901d-48e8-85dc-f49c07467f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|DOLocationID| count|\n",
      "+------------+------+\n",
      "|         148| 91601|\n",
      "|         243| 86795|\n",
      "|          31|  5526|\n",
      "|          85| 44509|\n",
      "|         137| 80098|\n",
      "|         251|  8525|\n",
      "|          65| 58888|\n",
      "|         255|105051|\n",
      "|          53| 19013|\n",
      "|         133| 27760|\n",
      "|          78| 74447|\n",
      "|         155| 42239|\n",
      "|         108| 21354|\n",
      "|         211| 54176|\n",
      "|         193| 19104|\n",
      "|          34| 12392|\n",
      "|         115|  9809|\n",
      "|         101|  7218|\n",
      "|         126| 59027|\n",
      "|          81| 38445|\n",
      "+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT DOLocationID, COUNT(*) AS count\n",
    "FROM trip_data\n",
    "GROUP BY DOLocationID\n",
    "'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba4b6df-994d-4602-9d76-dcd4dfbcdad5",
   "metadata": {},
   "source": [
    "## HV0003 운송사업자의 승차 지역별 트립 건수를 집계하고, \n",
    "\n",
    "## 가장 많은 운송사업자순으로 정렬하는 분석 쿼리  hvfhs_license_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "475dbe91-7906-451b-bf00-d49d4e3fcb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+------+\n",
      "|hvfhs_license_num|PULocationID| count|\n",
      "+-----------------+------------+------+\n",
      "|           HV0003|          61|163091|\n",
      "|           HV0003|          76|134198|\n",
      "|           HV0003|         132|114179|\n",
      "|           HV0003|          79|112017|\n",
      "|           HV0003|          37|110150|\n",
      "|           HV0003|          42|108070|\n",
      "|           HV0003|         138|104119|\n",
      "|           HV0003|         244| 97324|\n",
      "|           HV0003|          89| 95724|\n",
      "|           HV0003|          39| 94484|\n",
      "|           HV0003|         231| 94155|\n",
      "|           HV0003|           7| 92676|\n",
      "|           HV0003|          17| 90352|\n",
      "|           HV0003|         161| 90261|\n",
      "|           HV0003|         225| 88749|\n",
      "|           HV0003|         234| 88372|\n",
      "|           HV0003|         230| 86870|\n",
      "|           HV0003|         188| 84347|\n",
      "|           HV0003|          35| 82764|\n",
      "|           HV0003|         168| 82396|\n",
      "+-----------------+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT hvfhs_license_num, PULocationID, COUNT(*) AS count\n",
    "FROM trip_data\n",
    "WHERE hvfhs_license_num = 'HV0003'\n",
    "GROUP BY hvfhs_license_num, PULocationID\n",
    "ORDER BY count desc\n",
    "'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77254717-8e66-4bc7-9aff-4e449c8f1681",
   "metadata": {},
   "source": [
    "## 운송사별 운행 건수 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d29dff1-5490-4a99-9ee5-b532f91ca0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+\n",
      "|hvfhs_license_num|  COUNT|\n",
      "+-----------------+-------+\n",
      "|           HV0004| 336606|\n",
      "|           HV0005|3219535|\n",
      "|           HV0003|9836763|\n",
      "+-----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT hvfhs_license_num, COUNT(*) AS COUNT\n",
    "FROM TRIP_DATA\n",
    "GROUP BY hvfhs_license_num\n",
    "'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0644cba4-0113-4a71-a6a0-e414b401cedc",
   "metadata": {},
   "source": [
    "## 승차 위치 Borough별 운행 건수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ccbb1d19-6741-4381-859b-df0cf1948a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zone_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c79e165-9bdc-4e5d-8e03-99b0566425b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|      Borough|COUNT|\n",
      "+-------------+-----+\n",
      "|       Queens|   69|\n",
      "|          EWR|    1|\n",
      "|      Unknown|    2|\n",
      "|     Brooklyn|   61|\n",
      "|Staten Island|   20|\n",
      "|    Manhattan|   69|\n",
      "|        Bronx|   43|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT Borough, COUNT(*) AS COUNT\n",
    "FROM ZONE_DATA\n",
    "GROUP BY Borough\n",
    "'''\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19518b1-453c-4f7c-bfc6-8d24aa4560ee",
   "metadata": {},
   "source": [
    "## 서비스 존별 승차/하차 건수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6199c5bb-88f0-4166-9da2-cecf486fc680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|service_zone|  count|\n",
      "+------------+-------+\n",
      "|         EWR|    362|\n",
      "|         N/A|    845|\n",
      "| Yellow Zone|4025190|\n",
      "|    Airports| 319610|\n",
      "|   Boro Zone|9046897|\n",
      "+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# JOIN. 승차\n",
    "joined_df = trip_data.join(zone_data, trip_data['PULocationID'] == zone_data['LocationID'])\n",
    "joined_df.select('PULocationID','service_zone').groupby('service_zone').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bca79f70-4f79-4795-93b6-ceb3a430d176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|service_zone|  count|\n",
      "+------------+-------+\n",
      "|         EWR|  65066|\n",
      "|         N/A| 387759|\n",
      "| Yellow Zone|3643787|\n",
      "|    Airports| 411156|\n",
      "|   Boro Zone|8885136|\n",
      "+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# JOIN. 하차\n",
    "joined_df = trip_data.join(zone_data, trip_data['DOLocationID'] == zone_data['LocationID'])\n",
    "joined_df.select('DOLocationID','service_zone').groupby('service_zone').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a4ec69-56f2-4852-a8fc-ef4b0ea02d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72084362-b61d-4b2d-b695-d0a37388224e",
   "metadata": {},
   "source": [
    "# \"Bank Marketing\" 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f425bd89-7069-412f-980a-bab0424bf4e3",
   "metadata": {},
   "source": [
    "고객의 정보와 마케팅 캠페인 반응을 분석하여 마케팅 성공 여부 예측 모델링 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34260202-3125-4741-8b31-e93136e083a9",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e72a7ed2-3f1b-4bb5-8d2c-b7a8bfcddc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# SparkSession 생성\n",
    "spark = SparkSession.builder.appName(\"BankMarketing-Analy\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70040dc-1d80-4032-bf9e-cd6d8b108463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = './bank.csv'\n",
    "\n",
    "df = spark.read.csv(file_path, inferSchema = True, header = True,sep = ';')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f91205-5a95-480f-a8b4-6ec9435f041b",
   "metadata": {},
   "source": [
    "은행마케팅 캠페인 데이터셋 \n",
    "\n",
    "고객의 속성, 캠페인 연락 기록, 마지막 캠페인 성공여부(y) 를 포함하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4429158-05d7-43e3-9c16-2abcc95f7a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "|age|          job|marital|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
      "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "| 30|   unemployed|married|  primary|     no|   1787|     no|  no|cellular| 19|  oct|      79|       1|   -1|       0| unknown| no|\n",
      "| 33|     services|married|secondary|     no|   4789|    yes| yes|cellular| 11|  may|     220|       1|  339|       4| failure| no|\n",
      "| 35|   management| single| tertiary|     no|   1350|    yes|  no|cellular| 16|  apr|     185|       1|  330|       1| failure| no|\n",
      "| 30|   management|married| tertiary|     no|   1476|    yes| yes| unknown|  3|  jun|     199|       4|   -1|       0| unknown| no|\n",
      "| 59|  blue-collar|married|secondary|     no|      0|    yes|  no| unknown|  5|  may|     226|       1|   -1|       0| unknown| no|\n",
      "| 35|   management| single| tertiary|     no|    747|     no|  no|cellular| 23|  feb|     141|       2|  176|       3| failure| no|\n",
      "| 36|self-employed|married| tertiary|     no|    307|    yes|  no|cellular| 14|  may|     341|       1|  330|       2|   other| no|\n",
      "| 39|   technician|married|secondary|     no|    147|    yes|  no|cellular|  6|  may|     151|       2|   -1|       0| unknown| no|\n",
      "| 41| entrepreneur|married| tertiary|     no|    221|    yes|  no| unknown| 14|  may|      57|       2|   -1|       0| unknown| no|\n",
      "| 43|     services|married|  primary|     no|    -88|    yes| yes|cellular| 17|  apr|     313|       1|  147|       2| failure| no|\n",
      "| 39|     services|married|secondary|     no|   9374|    yes|  no| unknown| 20|  may|     273|       1|   -1|       0| unknown| no|\n",
      "| 43|       admin.|married|secondary|     no|    264|    yes|  no|cellular| 17|  apr|     113|       2|   -1|       0| unknown| no|\n",
      "| 36|   technician|married| tertiary|     no|   1109|     no|  no|cellular| 13|  aug|     328|       2|   -1|       0| unknown| no|\n",
      "| 20|      student| single|secondary|     no|    502|     no|  no|cellular| 30|  apr|     261|       1|   -1|       0| unknown|yes|\n",
      "| 31|  blue-collar|married|secondary|     no|    360|    yes| yes|cellular| 29|  jan|      89|       1|  241|       1| failure| no|\n",
      "| 40|   management|married| tertiary|     no|    194|     no| yes|cellular| 29|  aug|     189|       2|   -1|       0| unknown| no|\n",
      "| 56|   technician|married|secondary|     no|   4073|     no|  no|cellular| 27|  aug|     239|       5|   -1|       0| unknown| no|\n",
      "| 37|       admin.| single| tertiary|     no|   2317|    yes|  no|cellular| 20|  apr|     114|       1|  152|       2| failure| no|\n",
      "| 25|  blue-collar| single|  primary|     no|   -221|    yes|  no| unknown| 23|  may|     250|       1|   -1|       0| unknown| no|\n",
      "| 31|     services|married|secondary|     no|    132|     no|  no|cellular|  7|  jul|     148|       1|  152|       1|   other| no|\n",
      "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dbab25a-8742-4548-8bde-4a8f11b69af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-----+\n",
      "|duration|  y|count|\n",
      "+--------+---+-----+\n",
      "|       4| no|    1|\n",
      "|       5| no|    9|\n",
      "|       6| no|    2|\n",
      "|       7| no|    6|\n",
      "|       8| no|    9|\n",
      "|       9| no|   10|\n",
      "|      10| no|    9|\n",
      "|      11| no|    8|\n",
      "|      12| no|    5|\n",
      "|      13| no|    9|\n",
      "|      14| no|   10|\n",
      "|      15| no|   10|\n",
      "|      16| no|   11|\n",
      "|      17| no|    5|\n",
      "|      18| no|    7|\n",
      "|      19| no|    7|\n",
      "|      20| no|   11|\n",
      "|      21| no|    8|\n",
      "|      22| no|   11|\n",
      "|      23| no|    6|\n",
      "+--------+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"duration\", \"y\").groupBy(\"duration\", \"y\").count().orderBy(\"duration\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "603d12a2-dd93-4da5-a2c2-a52b4c15015f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-----+\n",
      "|duration|  y|count|\n",
      "+--------+---+-----+\n",
      "|      30|yes|    1|\n",
      "|      76|yes|    1|\n",
      "|      78|yes|    1|\n",
      "|      80|yes|    1|\n",
      "|      87|yes|    1|\n",
      "|      91|yes|    2|\n",
      "|      93|yes|    3|\n",
      "|      96|yes|    1|\n",
      "|      97|yes|    3|\n",
      "|     100|yes|    1|\n",
      "|     103|yes|    1|\n",
      "|     104|yes|    2|\n",
      "|     106|yes|    1|\n",
      "|     107|yes|    1|\n",
      "|     109|yes|    1|\n",
      "|     110|yes|    1|\n",
      "|     120|yes|    1|\n",
      "|     121|yes|    1|\n",
      "|     124|yes|    1|\n",
      "|     125|yes|    1|\n",
      "|     128|yes|    1|\n",
      "|     129|yes|    1|\n",
      "|     130|yes|    1|\n",
      "|     132|yes|    1|\n",
      "|     134|yes|    1|\n",
      "|     138|yes|    1|\n",
      "|     142|yes|    1|\n",
      "|     144|yes|    2|\n",
      "|     146|yes|    1|\n",
      "|     147|yes|    1|\n",
      "|     149|yes|    1|\n",
      "|     152|yes|    2|\n",
      "|     154|yes|    1|\n",
      "|     157|yes|    1|\n",
      "|     158|yes|    1|\n",
      "|     159|yes|    1|\n",
      "|     161|yes|    3|\n",
      "|     164|yes|    1|\n",
      "|     166|yes|    1|\n",
      "|     167|yes|    1|\n",
      "|     169|yes|    1|\n",
      "|     170|yes|    1|\n",
      "|     171|yes|    2|\n",
      "|     177|yes|    1|\n",
      "|     178|yes|    1|\n",
      "|     181|yes|    2|\n",
      "|     184|yes|    1|\n",
      "|     185|yes|    4|\n",
      "|     187|yes|    1|\n",
      "|     188|yes|    1|\n",
      "|     190|yes|    1|\n",
      "|     192|yes|    1|\n",
      "|     198|yes|    1|\n",
      "|     199|yes|    1|\n",
      "|     205|yes|    1|\n",
      "|     206|yes|    1|\n",
      "|     207|yes|    2|\n",
      "|     212|yes|    1|\n",
      "|     213|yes|    3|\n",
      "|     214|yes|    1|\n",
      "|     215|yes|    2|\n",
      "|     216|yes|    2|\n",
      "|     218|yes|    1|\n",
      "|     220|yes|    1|\n",
      "|     221|yes|    1|\n",
      "|     222|yes|    2|\n",
      "|     223|yes|    3|\n",
      "|     224|yes|    3|\n",
      "|     225|yes|    1|\n",
      "|     226|yes|    2|\n",
      "|     227|yes|    1|\n",
      "|     228|yes|    1|\n",
      "|     229|yes|    1|\n",
      "|     230|yes|    2|\n",
      "|     231|yes|    1|\n",
      "|     232|yes|    2|\n",
      "|     234|yes|    1|\n",
      "|     238|yes|    1|\n",
      "|     239|yes|    3|\n",
      "|     242|yes|    1|\n",
      "|     243|yes|    1|\n",
      "|     244|yes|    1|\n",
      "|     245|yes|    2|\n",
      "|     249|yes|    2|\n",
      "|     250|yes|    3|\n",
      "|     251|yes|    1|\n",
      "|     252|yes|    2|\n",
      "|     253|yes|    1|\n",
      "|     254|yes|    1|\n",
      "|     255|yes|    1|\n",
      "|     256|yes|    1|\n",
      "|     257|yes|    1|\n",
      "|     258|yes|    2|\n",
      "|     260|yes|    2|\n",
      "|     261|yes|    3|\n",
      "|     262|yes|    2|\n",
      "|     264|yes|    2|\n",
      "|     267|yes|    2|\n",
      "|     268|yes|    2|\n",
      "|     269|yes|    2|\n",
      "+--------+---+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"duration\", \"y\").count().filter(\"y = 'yes'\").orderBy(\"duration\").show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462c836-72fd-4176-a1e3-77961f056624",
   "metadata": {},
   "source": [
    "### duration 칼럼\n",
    "떄문에 정확도가 1이 나옴\n",
    "즉, 이 컬럼만으로도 정답 예측이 가기 때문에 드랍하고 다시하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c13eb187-71dd-424a-9319-626276abeec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"duration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cf4702-25a1-4061-a9a6-17a95988ff39",
   "metadata": {},
   "source": [
    "## 2. 데이터 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d564ed-02eb-418c-9e23-70298a4c608a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+-----+--------+--------+---+\n",
      "|age|job|marital|education|default|balance|housing|loan|contact|day|month|campaign|pdays|previous|poutcome|  y|\n",
      "+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+-----+--------+--------+---+\n",
      "|  0|  0|      0|        0|      0|      0|      0|   0|      0|  0|    0|       0|    0|       0|       0|  0|\n",
      "+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+-----+--------+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 결측치 알아보기\n",
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "\n",
    "df.select([\n",
    "    count(when(col(c).isNull() | isnan(c), c)).alias(c)\n",
    "    for c in df.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07d76b58-9e8f-424f-ad63-73b6840568ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|          job|count|\n",
      "+-------------+-----+\n",
      "|   management|  969|\n",
      "|  blue-collar|  946|\n",
      "|   technician|  768|\n",
      "|       admin.|  478|\n",
      "|     services|  417|\n",
      "|      retired|  230|\n",
      "|self-employed|  183|\n",
      "| entrepreneur|  168|\n",
      "|   unemployed|  128|\n",
      "|    housemaid|  112|\n",
      "|      student|   84|\n",
      "|      unknown|   38|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"job\").count().orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3ca86b-e5ca-4573-8826-d57ea6ce4967",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98c1af4e-1466-4c7a-bb28-dc3933d4def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타겟변수 인코딩\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "label_indexer = StringIndexer(inputCol = 'y', outputCol = 'label_y')\n",
    "df = label_indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c188b8b-773f-488e-ad82-f1db22ea03cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- label_y: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(\"y\",'day')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c713f7a4-1139-4592-8a3a-400c3f9e238c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructField('age', IntegerType(), True),\n",
       " StructField('job', StringType(), True),\n",
       " StructField('marital', StringType(), True),\n",
       " StructField('education', StringType(), True),\n",
       " StructField('default', StringType(), True),\n",
       " StructField('balance', IntegerType(), True),\n",
       " StructField('housing', StringType(), True),\n",
       " StructField('loan', StringType(), True),\n",
       " StructField('contact', StringType(), True),\n",
       " StructField('month', StringType(), True),\n",
       " StructField('campaign', IntegerType(), True),\n",
       " StructField('pdays', IntegerType(), True),\n",
       " StructField('previous', IntegerType(), True),\n",
       " StructField('poutcome', StringType(), True),\n",
       " StructField('label_y', DoubleType(), False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e14aaf03-441c-425f-be9e-e6f8e6ba8d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-------+---------+-------+-------+-------+----+--------+-----+--------+-----+--------+--------+-------+\n",
      "|age|          job|marital|education|default|balance|housing|loan| contact|month|campaign|pdays|previous|poutcome|label_y|\n",
      "+---+-------------+-------+---------+-------+-------+-------+----+--------+-----+--------+-----+--------+--------+-------+\n",
      "| 30|   unemployed|married|  primary|     no|   1787|     no|  no|cellular|  oct|       1|   -1|       0| unknown|    0.0|\n",
      "| 33|     services|married|secondary|     no|   4789|    yes| yes|cellular|  may|       1|  339|       4| failure|    0.0|\n",
      "| 35|   management| single| tertiary|     no|   1350|    yes|  no|cellular|  apr|       1|  330|       1| failure|    0.0|\n",
      "| 30|   management|married| tertiary|     no|   1476|    yes| yes| unknown|  jun|       4|   -1|       0| unknown|    0.0|\n",
      "| 59|  blue-collar|married|secondary|     no|      0|    yes|  no| unknown|  may|       1|   -1|       0| unknown|    0.0|\n",
      "| 35|   management| single| tertiary|     no|    747|     no|  no|cellular|  feb|       2|  176|       3| failure|    0.0|\n",
      "| 36|self-employed|married| tertiary|     no|    307|    yes|  no|cellular|  may|       1|  330|       2|   other|    0.0|\n",
      "| 39|   technician|married|secondary|     no|    147|    yes|  no|cellular|  may|       2|   -1|       0| unknown|    0.0|\n",
      "| 41| entrepreneur|married| tertiary|     no|    221|    yes|  no| unknown|  may|       2|   -1|       0| unknown|    0.0|\n",
      "| 43|     services|married|  primary|     no|    -88|    yes| yes|cellular|  apr|       1|  147|       2| failure|    0.0|\n",
      "| 39|     services|married|secondary|     no|   9374|    yes|  no| unknown|  may|       1|   -1|       0| unknown|    0.0|\n",
      "| 43|       admin.|married|secondary|     no|    264|    yes|  no|cellular|  apr|       2|   -1|       0| unknown|    0.0|\n",
      "| 36|   technician|married| tertiary|     no|   1109|     no|  no|cellular|  aug|       2|   -1|       0| unknown|    0.0|\n",
      "| 20|      student| single|secondary|     no|    502|     no|  no|cellular|  apr|       1|   -1|       0| unknown|    1.0|\n",
      "| 31|  blue-collar|married|secondary|     no|    360|    yes| yes|cellular|  jan|       1|  241|       1| failure|    0.0|\n",
      "| 40|   management|married| tertiary|     no|    194|     no| yes|cellular|  aug|       2|   -1|       0| unknown|    0.0|\n",
      "| 56|   technician|married|secondary|     no|   4073|     no|  no|cellular|  aug|       5|   -1|       0| unknown|    0.0|\n",
      "| 37|       admin.| single| tertiary|     no|   2317|    yes|  no|cellular|  apr|       1|  152|       2| failure|    0.0|\n",
      "| 25|  blue-collar| single|  primary|     no|   -221|    yes|  no| unknown|  may|       1|   -1|       0| unknown|    0.0|\n",
      "| 31|     services|married|secondary|     no|    132|     no|  no|cellular|  jul|       1|  152|       1|   other|    0.0|\n",
      "+---+-------------+-------+---------+-------+-------+-------+----+--------+-----+--------+-----+--------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701ac83a-4ebb-4346-9280-e06bb930a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c98046d-0f0e-4449-9d11-0cfcde88b8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+-------+-------+----+---------+-----+--------+---------+-------------+---------------+-------------+-------------+----------+-------------+-----------+--------------+---------------+--------------+----------------+--------------+--------------+-------------+--------------+--------------+---------------+\n",
      "|    job|marital|education|default|housing|loan|  contact|month|poutcome|job_index|marital_index|education_index|default_index|housing_index|loan_index|contact_index|month_index|poutcome_index|     job_onehot|marital_onehot|education_onehot|default_onehot|housing_onehot|  loan_onehot|contact_onehot|  month_onehot|poutcome_onehot|\n",
      "+-------+-------+---------+-------+-------+----+---------+-----+--------+---------+-------------+---------------+-------------+-------------+----------+-------------+-----------+--------------+---------------+--------------+----------------+--------------+--------------+-------------+--------------+--------------+---------------+\n",
      "|student| single|  primary|     no|     no|  no| cellular|  jul| unknown|     10.0|          1.0|            2.0|          0.0|          1.0|       0.0|          0.0|        1.0|           0.0|(13,[10],[1.0])| (4,[1],[1.0])|   (5,[2],[1.0])| (3,[0],[1.0])| (3,[1],[1.0])|(3,[0],[1.0])| (4,[0],[1.0])|(13,[1],[1.0])|  (5,[0],[1.0])|\n",
      "|student| single|secondary|     no|     no|  no| cellular|  jul| unknown|     10.0|          1.0|            0.0|          0.0|          1.0|       0.0|          0.0|        1.0|           0.0|(13,[10],[1.0])| (4,[1],[1.0])|   (5,[0],[1.0])| (3,[0],[1.0])| (3,[1],[1.0])|(3,[0],[1.0])| (4,[0],[1.0])|(13,[1],[1.0])|  (5,[0],[1.0])|\n",
      "|student| single|  unknown|     no|     no|  no| cellular|  feb| unknown|     10.0|          1.0|            3.0|          0.0|          1.0|       0.0|          0.0|        6.0|           0.0|(13,[10],[1.0])| (4,[1],[1.0])|   (5,[3],[1.0])| (3,[0],[1.0])| (3,[1],[1.0])|(3,[0],[1.0])| (4,[0],[1.0])|(13,[6],[1.0])|  (5,[0],[1.0])|\n",
      "|student| single|secondary|     no|     no|  no|telephone|  may| failure|     10.0|          1.0|            0.0|          0.0|          1.0|       0.0|          2.0|        0.0|           1.0|(13,[10],[1.0])| (4,[1],[1.0])|   (5,[0],[1.0])| (3,[0],[1.0])| (3,[1],[1.0])|(3,[0],[1.0])| (4,[2],[1.0])|(13,[0],[1.0])|  (5,[1],[1.0])|\n",
      "|student| single|secondary|     no|     no|  no| cellular|  apr| unknown|     10.0|          1.0|            0.0|          0.0|          1.0|       0.0|          0.0|        5.0|           0.0|(13,[10],[1.0])| (4,[1],[1.0])|   (5,[0],[1.0])| (3,[0],[1.0])| (3,[1],[1.0])|(3,[0],[1.0])| (4,[0],[1.0])|(13,[5],[1.0])|  (5,[0],[1.0])|\n",
      "+-------+-------+---------+-------+-------+----+---------+-----+--------+---------+-------------+---------------+-------------+-------------+----------+-------------+-----------+--------------+---------------+--------------+----------------+--------------+--------------+-------------+--------------+--------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 카테고리형 변수 인코딩\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# column 이 string인 칼럼 추출\n",
    "string_cols = [field.name for field in df.schema.fields if field.dataType.simpleString() == 'string']\n",
    "\n",
    "# StringIndexer 리스트 생성)\n",
    "indexers = [StringIndexer(inputCol = c, outputCol = c+'_index', handleInvalid = 'keep') for c in string_cols]\n",
    "\n",
    "# one-hot encoding\n",
    "encoder = OneHotEncoder(inputCols = [c+'_index' for c in string_cols],\n",
    "                        outputCols = [c +'_onehot' for c in string_cols],\n",
    "                        handleInvalid = 'keep') # 학습 시 보지 못한 값이 테스트 데이터에 있어도 에러가 안 나게 처리하는 옵션\n",
    "\n",
    "# 파이프라인 스테이지 정의\n",
    "stages = indexers + [encoder]\n",
    "pipeline = Pipeline(stages = stages)\n",
    "\n",
    "# 학습 및 변환\n",
    "model = pipeline.fit(train_df) # 원핫인코딩의 학습\n",
    "df_encoded = model.transform(train_df)\n",
    "df_encoded_test = model.transform(test_df)\n",
    "\n",
    "# 결과확인\n",
    "df_encoded.select(string_cols + [c+'_index' for c in string_cols] + [c+ '_onehot' for c in string_cols]).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d82467-55d0-49e2-8a16-24b4908078cb",
   "metadata": {},
   "source": [
    "⭐ spark 에서는 원핫 인코딩도 **'학습'** 의 과정을 거친다는 개념이 들어가 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc933a2e-49dc-4543-be2d-4f31d64278dc",
   "metadata": {},
   "source": [
    "따라서, train/test로 나눈 뒤에 train 데이터로만 학습하고 test에 적용해야한다.!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43856a67-f39a-4304-ae30-a1428a5703ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- label_y: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "847b1862-4c16-47d1-a7a5-4057e2383d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructField('age', IntegerType(), True),\n",
       " StructField('job', StringType(), True),\n",
       " StructField('marital', StringType(), True),\n",
       " StructField('education', StringType(), True),\n",
       " StructField('default', StringType(), True),\n",
       " StructField('balance', IntegerType(), True),\n",
       " StructField('housing', StringType(), True),\n",
       " StructField('loan', StringType(), True),\n",
       " StructField('contact', StringType(), True),\n",
       " StructField('month', StringType(), True),\n",
       " StructField('campaign', IntegerType(), True),\n",
       " StructField('pdays', IntegerType(), True),\n",
       " StructField('previous', IntegerType(), True),\n",
       " StructField('poutcome', StringType(), True),\n",
       " StructField('label_y', DoubleType(), False)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0ad64dc-cbd2-4a14-afc5-f108854c2176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name: age, Data Type: int\n",
      "Column Name: job, Data Type: string\n",
      "Column Name: marital, Data Type: string\n",
      "Column Name: education, Data Type: string\n",
      "Column Name: default, Data Type: string\n",
      "Column Name: balance, Data Type: int\n",
      "Column Name: housing, Data Type: string\n",
      "Column Name: loan, Data Type: string\n",
      "Column Name: contact, Data Type: string\n",
      "Column Name: month, Data Type: string\n",
      "Column Name: campaign, Data Type: int\n",
      "Column Name: pdays, Data Type: int\n",
      "Column Name: previous, Data Type: int\n",
      "Column Name: poutcome, Data Type: string\n",
      "Column Name: label_y, Data Type: double\n",
      "Column Name: job_index, Data Type: double\n",
      "Column Name: marital_index, Data Type: double\n",
      "Column Name: education_index, Data Type: double\n",
      "Column Name: default_index, Data Type: double\n",
      "Column Name: housing_index, Data Type: double\n",
      "Column Name: loan_index, Data Type: double\n",
      "Column Name: contact_index, Data Type: double\n",
      "Column Name: month_index, Data Type: double\n",
      "Column Name: poutcome_index, Data Type: double\n",
      "Column Name: job_onehot, Data Type: vector\n",
      "Column Name: marital_onehot, Data Type: vector\n",
      "Column Name: education_onehot, Data Type: vector\n",
      "Column Name: default_onehot, Data Type: vector\n",
      "Column Name: housing_onehot, Data Type: vector\n",
      "Column Name: loan_onehot, Data Type: vector\n",
      "Column Name: contact_onehot, Data Type: vector\n",
      "Column Name: month_onehot, Data Type: vector\n",
      "Column Name: poutcome_onehot, Data Type: vector\n"
     ]
    }
   ],
   "source": [
    "for field in df_encoded.schema.fields:\n",
    "    print(f\"Column Name: {field.name}, Data Type: {field.dataType.simpleString()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "541f8369-b8a0-4247-aee4-e27149257583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'balance', 'campaign', 'pdays', 'previous', 'job_onehot', 'marital_onehot', 'education_onehot', 'default_onehot', 'housing_onehot', 'loan_onehot', 'contact_onehot', 'month_onehot', 'poutcome_onehot']\n"
     ]
    }
   ],
   "source": [
    "# 특징벡터 만들기\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# 수치형 컬럼\n",
    "integer_cols = [field.name for field in df_encoded.schema.fields if field.dataType.simpleString() == 'int']\n",
    "\n",
    "# 원핫인코딩 컬럼\n",
    "onehot_cols = [col for col in df_encoded.columns if col.endswith('_onehot')]\n",
    "\n",
    "# 수치형 + 인코딩된 범주형 합치기\n",
    "all_features = [col for col in (integer_cols + onehot_cols) if col != 'label_y']\n",
    "\n",
    "# 벡터화\n",
    "assembler = VectorAssembler(inputCols=all_features, outputCol='features')\n",
    "df_final = assembler.transform(df_encoded)\n",
    "df_final_test = assembler.transform(df_encoded_test)\n",
    "\n",
    "print(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc591f9a-28f2-492d-b00c-03d39644379b",
   "metadata": {},
   "source": [
    "## 4. 모델생성 및 확인 + 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a7336-33fe-4a4d-8962-4201f9ef8cc9",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9209f4d-1b1d-4451-afb3-65c6a9703d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label_y')\n",
    "pipeline = Pipeline(stages=[lr])\n",
    "model = pipeline.fit(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5e47d6f-2dc9-4488-8d8d-807b2052d6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+-------+----------+-----------------------------------------+\n",
      "|features                                                                                            |label_y|prediction|probability                              |\n",
      "+----------------------------------------------------------------------------------------------------+-------+----------+-----------------------------------------+\n",
      "|(58,[0,2,3,15,19,25,27,31,33,36,46,53],[19.0,3.0,-1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])         |0.0    |0.0       |[0.8104264939386411,0.18957350606135892] |\n",
      "|(58,[0,1,2,3,15,19,22,27,31,33,36,46,53],[20.0,1191.0,1.0,-1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0    |0.0       |[0.6655290841626393,0.33447091583736066] |\n",
      "|(58,[0,1,2,3,9,19,22,27,30,33,37,40,53],[21.0,1903.0,2.0,-1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]) |0.0    |0.0       |[0.9738706598246873,0.026129340175312654]|\n",
      "|(58,[0,1,2,3,15,19,25,27,30,33,37,40,53],[21.0,137.0,3.0,-1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]) |0.0    |0.0       |[0.9678770604008645,0.03212293959913548] |\n",
      "|(58,[0,1,2,3,15,19,23,27,31,34,36,43,53],[22.0,1161.0,1.0,-1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0    |0.0       |[0.653912266818301,0.34608773318169905]  |\n",
      "+----------------------------------------------------------------------------------------------------+-------+----------+-----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 결과 확인\n",
    "predictions = model.transform(df_final_test)\n",
    "predictions.select('features', 'label_y', 'prediction', 'probability').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91fcfb20-bb79-48a7-9614-b69286bddf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.6593\n"
     ]
    }
   ],
   "source": [
    "# 모델 성능 평가하기\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol = 'label_y',\n",
    "    rawPredictionCol='rawPrediction', \n",
    "    metricName= 'areaUnderROC'\n",
    ")\n",
    "\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f'ROC AUC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8379a5e0-a92f-41a8-a7fe-788176f8d81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8917\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# 정확도\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='label_y', predictionCol='prediction', metricName='accuracy'\n",
    ")\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7caf50-c12b-4209-bda4-e1c9df01f304",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2e17e98-6a87-4c20-9059-9c0607ddcda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7076\n",
      "Accuracy: 0.8882\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label_y', numTrees=100)\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "model = pipeline.fit(df_final)\n",
    "predictions = model.transform(df_final_test)\n",
    "\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f'ROC AUC: {auc:.4f}')\n",
    "\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d40bc23-a4ef-4b12-b67b-cf4f293cf8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 0.07208277274083542\n",
      "balance: 0.044496703825274105\n",
      "campaign: 0.023260679470037186\n",
      "pdays: 0.08745533676086642\n",
      "previous: 0.05944854743959491\n",
      "job_onehot: 0.006047665515205972\n",
      "marital_onehot: 0.010606755644969518\n",
      "education_onehot: 0.004747390029002987\n",
      "default_onehot: 0.0022706076994766086\n",
      "housing_onehot: 0.001201413960583692\n",
      "loan_onehot: 0.025695794252365723\n",
      "contact_onehot: 0.001736960612841787\n",
      "month_onehot: 0.00037799249910343383\n",
      "poutcome_onehot: 0.003189676777006131\n"
     ]
    }
   ],
   "source": [
    "# 파이프라인 내 모델 중 마지막 단계가 분류기라고 가정\n",
    "rf_model = model.stages[-1]  # 마지막 단계 모델 꺼내기\n",
    "\n",
    "# 피처 중요도 출력\n",
    "importances = rf_model.featureImportances\n",
    "\n",
    "for name, imp in zip(all_features, importances):\n",
    "    print(f\"{name}: {imp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5a8fd8-7937-468e-941c-3279ee02bb44",
   "metadata": {},
   "source": [
    " **정확도(Accuracy)** 는 높은 편이고 거의 차이 없음\n",
    "0.89 vs 0.88 → 큰 차이 아님 (±0.01)\n",
    "\n",
    "만약 데이터가 불균형하다면, 정확도는 믿을 수 있는 지표가 아니다.\n",
    "\n",
    "AUC는 분류 모델이 얼마나 잘 구분을 하는지 보여주는 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f289b293-d39b-4066-b24c-1cdc7d76610c",
   "metadata": {},
   "source": [
    "🔍 **데이터는 같고 모델만 다른데 AUC가 왜 다르냐?**\n",
    "\n",
    "✅ 1. 모델 구조에 따라 예측 방식이 다름\n",
    "\n",
    "AUC는 단순히 맞았냐 틀렸냐가 아니라 모델이 예측한 \"확률(probability)\"의 분포를 기준으로 계산돼요.\n",
    "\n",
    "Logistic Regression: 선형 decision boundary 기반\n",
    "\n",
    "Random Forest: 앙상블 트리 기반, 비선형 경계\n",
    "\n",
    "Gradient Boosting: 오차 줄이는 방향으로 반복 학습\n",
    "\n",
    "➡️ 같은 데이터라도 모델마다 확률 분포가 다르게 나와요.\n",
    "\n",
    "그 결과 ROC 곡선의 모양과 AUC 값도 달라집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d82dcb-4ef2-47c0-8e5b-7cbbbf70f4a5",
   "metadata": {},
   "source": [
    "### Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc1bc333-0812-49f0-801d-2ec4ab14d370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.6799\n",
      "Accuracy: 0.8813\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(labelCol=\"label_y\", featuresCol=\"features\", maxIter=50, maxDepth=5)\n",
    "model = gbt.fit(df_final)\n",
    "predictions = model.transform(df_final_test)\n",
    "\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f'ROC AUC: {auc:.4f}')\n",
    "\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74edda8f-57fc-4263-9852-b6d8712aca2d",
   "metadata": {},
   "source": [
    "**전처리를 하지 않았을 경우 AUC는 0.6 ~0.7 사이, 정확도는 0.8 ~0.9 사이의 값을 갖는다.**\n",
    "\n",
    "따라서, 정확도를 높이기 위한 데이터 EDA를 실시!🏋️‍♀️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5f2ad62-6710-42d3-9b7c-8cf4eb8630cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

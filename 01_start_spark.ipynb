{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d29976a-c919-4fc2-b6fb-fa520000b9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73472d0b-2b3a-4c3c-b225-19fc09b12405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63af8ef4-0a75-4bdf-8fc6-b24c0788172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.6\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef9ec460-2564-4401-90f9-0d8b3f19187a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"17.0.8.1\" 2023-08-24\n",
      "OpenJDK Runtime Environment (build 17.0.8.1+1-Ubuntu-0ubuntu122.04)\n",
      "OpenJDK 64-Bit Server VM (build 17.0.8.1+1-Ubuntu-0ubuntu122.04, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc8cb1bf-6cad-4ec8-84ec-adb69e9b0958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pyspark\n",
      "Version: 3.5.0\n",
      "Summary: Apache Spark Python API\n",
      "Home-page: https://github.com/apache/spark/tree/master/python\n",
      "Author: Spark Developers\n",
      "Author-email: dev@spark.apache.org\n",
      "License: http://www.apache.org/licenses/LICENSE-2.0\n",
      "Location: /usr/local/spark/python\n",
      "Requires: py4j\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4a9667a-0838-49fe-922b-4391d6738bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/spark'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark_home\n",
    "import os\n",
    "os.environ.get(\"SPARK_HOME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4283419-3e61-4fd6-af35-b1c17fd3e295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# java_home\n",
    "os.environ.get(\"JAVA_HOME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6970555c-acd5-42ad-ba8e-3f6d4ff1fb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip:/usr/local/spark/python:'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get(\"PYTHONPATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9714a152-f1c7-4ed2-9e94-2e8c0cb71fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be1d6273-2e27-43a9-bf72-316d5e338a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('pyspark example1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e52bad1a-77da-4a15-845b-0340904ff7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://6c8dcd110e07:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark example1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f06341fc590>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5338a5b-a05c-4dd1-9c4e-1c7f0a82d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34ae3a13-9fba-45f6-b554-de72b800bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('pyspark example1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ee74206-432d-4087-a709-f0aa025fd3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://6c8dcd110e07:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark example1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0634246310>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03ab12e5-ddb4-42c2-938e-368dd43bc2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [('Ailce',1),('Job',2),('Charlie',3)]\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "343b6b9d-1f46-4ece-be58-80f89f481616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Name[1]'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = spark.createDataFrame(data, ['Name','Value']) # spark의 분산객체: 데이터프레임 형식\n",
    "data1[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf30359b-0cbb-4975-b74c-a0ae43721526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|  Ailce|    1|\n",
      "|    Job|    2|\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33e2116-7a8c-4b9a-bd7f-dd6d19f415cf",
   "metadata": {},
   "source": [
    "# RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dd7c32b-4b5c-4cad-b3d6-051a264e6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('pyspark example1').getOrCreate() # 기존에 있는 거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af624da0-9270-4537-8480-d9b00c2d1308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[28] at readRDDFromFile at PythonRDD.scala:289"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize([1,2,3,4,5])\n",
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a26fadc5-c28f-4814-9fa5-3c1e081a18a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Value: bigint]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bec23037-da88-49c1-a6fe-246e23aa0687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5) # 객체를 생성 - n개를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "271272c5-26de-4dee-b2ca-2ab49657e4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://6c8dcd110e07:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark example1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0634246310>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71ce70e4-c3df-45ef-b45f-90220634740a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[33] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map연산\n",
    "rdd_1 = rdd.map(lambda x: x*x)\n",
    "rdd_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4924e530-cd8f-4b6d-b3d4-a42cfefade14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_1.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5169ae0e-63f6-415d-ad96-3d753c25489c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f89e2231-f021-4e0d-a55e-d4f496b40b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_1.collect() # 전부 다 가지고오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9702546-666a-44ca-9f12-2e8337c09399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Name|Value|\n",
      "+----+-----+\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.filter(data1.Name == 'Bob').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "713e8ca7-c7aa-48c0-966e-cdc53d646932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.filter(data1.Value > 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "809f0a6d-fb55-4716-bcfe-9f41b6d7d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.createOrReplaceTempView('people') # 메모리상에 뷰 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e38c31cd-5673-4324-91ce-f68fd5b1a18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Value|\n",
      "+-------+-----+\n",
      "|  Ailce|    1|\n",
      "|    Job|    2|\n",
      "|Charlie|    3|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from people').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7ff3f67-513c-4613-b48c-adcd5c9eb395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   Name|\n",
      "+-------+\n",
      "|  Ailce|\n",
      "|    Job|\n",
      "|Charlie|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select Name from people').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d32ab6ad-68c3-4c72-9d11-63d1e910ba49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Name|Value|\n",
      "+----+-----+\n",
      "| Job|    2|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from people where name = 'Job'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a998c3cb-ae67-4596-a7ef-a20846a2abfa",
   "metadata": {},
   "source": [
    "# MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7220654-c77b-48f1-af9e-c0f164bda43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "be9e7604-fdbe-4013-8475-90650e4cbc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c83ca993-3a51-4d7d-9c6c-4b46fa48ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee0bd036-47ae-482a-bb6d-74f360f6a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_age = [('Ailce',25),('Bob',30),('Charlie',33)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df25c198-43b4-449d-870e-ae9950509ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: bigint]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = spark.createDataFrame(data_age, ['Name','Age'])\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8b1829d1-c82f-4082-81d4-52235cacc738",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = ['Age'], outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d86e5ab7-1d38-46f0-af6b-5a0f27639d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_df = assembler.transform(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bff9e678-4ec5-4aee-bba5-94033a3dbe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol = 'features',labelCol = 'Age')\n",
    "model = lr.fit(vector_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7cb039da-574e-4c03-a9aa-7d27dc15fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.transform(vector_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7929c466-0a8a-4366-a24f-e4ba019838be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------+-----------------+\n",
      "|   Name|Age|features|       prediction|\n",
      "+-------+---+--------+-----------------+\n",
      "|  Ailce| 25|  [25.0]|24.99999999999993|\n",
      "|    Bob| 30|  [30.0]|30.00000000000001|\n",
      "|Charlie| 33|  [33.0]|33.00000000000006|\n",
      "+-------+---+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1d7370ec-d5b3-464e-9dd8-b2c234dbe793",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe258de-5b9c-4506-b788-419792b7d948",
   "metadata": {},
   "source": [
    "# streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "00a1b010-e165-4f40-b78c-53c7581c6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5e7327a8-7fb5-41c2-9ba4-48bb896c3597",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('pyspark example1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f4122eaa-6842-474f-a133-9a74c7d44678",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark.readStream.format('socket').option('host','localhost')\\\n",
    ".option('port',9999).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "47940d99-3b75-4e12-b2b7-a38ec66ade90",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = lines.select(explode(split(lines.value,' ')).alias('word'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8f029555-d737-457c-aa5a-eb4b59c08196",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
